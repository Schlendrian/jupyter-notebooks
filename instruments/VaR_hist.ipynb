{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyvacon\n",
    "import pyvacon.marketdata.testdata as mkt_testdata\n",
    "import pyvacon.tools.enums as enums\n",
    "import pyvacon.marketdata.plot as mkt_plot\n",
    "import pyvacon.models.plot as model_plot\n",
    "import pyvacon.models.tools as model_tools\n",
    "import pyvacon.analytics as analytics\n",
    "import pyvacon.tools.converter as converter\n",
    "\n",
    "from matplotlib.lines import Line2D\n",
    "from matplotlib.patches import Patch, Rectangle\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "import matplotlib.dates as mdates\n",
    "import matplotlib.transforms as mtransforms\n",
    "%matplotlib inline\n",
    "\n",
    "import datetime as dt\n",
    "import math\n",
    "import numpy as np\n",
    "\n",
    "from scipy import stats\n",
    "import plotly\n",
    "import plotly.graph_objs as go\n",
    "from plotly.offline import init_notebook_mode, iplot\n",
    "init_notebook_mode(connected=True)\n",
    "\n",
    "import pandas as pd\n",
    "from pandas.plotting import register_matplotlib_converters\n",
    "register_matplotlib_converters()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Constants and Switches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "color_main = 'tab:blue'\n",
    "color_highlight = 'tab:orange'\n",
    "grid_alpha = 0.4\n",
    "daycounter_type_standard = enums.DayCounter.ACTACT\n",
    "interpolation_type_standard = enums.InterpolationType.LINEAR\n",
    "extrapolation_type_standard = enums.ExtrapolationType.NONE\n",
    "\n",
    "scenario_construction_type = 'relative' # absolute or relative\n",
    "timeinterval = 1 # number of business days (TARGET2), i.e. the number of rows in the Excel sheet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "## Value at risk\n",
    "Value at risk (VaR) is a measure for the risk in a portfolio of financial assets. Given a time horizon of $n$ days and a confidence level $\\alpha$, the VaR is the loss of value, which has the probability $\\alpha$ not to be exceeded within the next $n$ days. In other words, the VaR is the $\\alpha$-quantile of the distribution of loss in the value of a portfolio other the next $n$ days."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# xrange = np.arange(-4,4,0.01)\n",
    "# norm = go.Scatter(x=xrange, \n",
    "#                   y=stats.norm(loc=0, scale=1).pdf(xrange), \n",
    "#                   mode='lines',\n",
    "#                   name='Normal'\n",
    "#                  )\n",
    "# data = [norm]\n",
    "# iplot(data, show_link=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The different methods for estimating the value at risk can be put into two major categories: Those using analytical models and those using simulations.\n",
    "\n",
    "The goal of **analytical** methods is to define a probability distribution, which approximates the actual probability distribution of the portfolio value. One can then write down a closed formula for the value at risk.\n",
    "\n",
    "**Simulation**-based methods simulate the change in value over the next $n$ days and use the resulting relative frequency distribution to 'read off' the value at risk."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Historical simulation\n",
    "A very popular way of simulating changes in value uses past market data to estimate what will happen in the future. To do so, we first have to identify all market variables affecting the portfolio value. Then we collect data on how these variables moved over the past $k+n$ days. This allows us to calculate $k$ historical scenarios of what can happen in $n$ days. Assuming that the market will behave in the future as it did in the past, we can compute the portfolio value in each of these scenarios. This provides us with a relative frequency distribution, which we then use to determine the value at risk.\n",
    "\n",
    "The goal of this notebook is to give a simple example of such a historical simulation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scenario Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load test data from an Excel file\n",
    "xl = pd.ExcelFile('TestDaten.xlsx')\n",
    "#print(xl.sheet_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_EONIA = xl.parse('EONIA')\n",
    "data_EONIA = pd.DataFrame(data_EONIA,\n",
    "                       columns = [\n",
    "                           'stichtag6',\n",
    "                           'prz_bs1t',\n",
    "                           'prz_bs1m',\n",
    "                           'prz_bs2m',\n",
    "                           'prz_bs3m',\n",
    "                           'prz_bs4m',\n",
    "                           'prz_bs5m',\n",
    "                           'prz_bs6m',\n",
    "                           'prz_bs7m',\n",
    "                           'prz_bs8m',\n",
    "                           'prz_bs9m',\n",
    "                           'prz_bs10m',\n",
    "                           'prz_bs11m',\n",
    "                           'prz_bs1j',\n",
    "                           'prz_bs2j',\n",
    "                           'prz_bs3j',\n",
    "                           'prz_bs4j',\n",
    "                           'prz_bs5j',\n",
    "                           'prz_bs6j',\n",
    "                           'prz_bs7j',\n",
    "                           'prz_bs8j',\n",
    "                           'prz_bs9j',\n",
    "                           'prz_bs10j'\n",
    "                       ])\n",
    "\n",
    "\n",
    "# convert Excel dates to a human-readable format and add them to the data frame as a new column\n",
    "data_EONIA['datum'] = pd.TimedeltaIndex(data_EONIA['stichtag6'], unit='d') + dt.datetime(1899, 12, 30)\n",
    "#print(data_EONIA)\n",
    "\n",
    "# define the reference date as the date of the first market data sample (rows are ordered by date desc)\n",
    "refdate = dt.datetime(year = data_EONIA.iloc[0]['datum'].year, month = data_EONIA.iloc[0]['datum'].month, day = data_EONIA.iloc[0]['datum'].day)\n",
    "#refdate = dt.datetime(data_EONIA.iloc[0]['datum'])\n",
    "\n",
    "# expiry in years\n",
    "sampling_points_EONIA_yf = [1/365] # 1 day\n",
    "sampling_points_EONIA_yf.extend( (np.arange(11)+1)/12 ) # 1 to 11 months\n",
    "sampling_points_EONIA_yf.extend(np.arange(10)+1) # 1 to 10 years\n",
    "#print(sampling_points_EONIA_yf)\n",
    "\n",
    "# convert the year fractions into dates (using the reference date defined above)\n",
    "sampling_points_EONIA_dates = []\n",
    "sampling_points_EONIA_dates.append(refdate + dt.timedelta(days = 1))\n",
    "for i in range(11):\n",
    "    sampling_points_EONIA_dates.append(refdate + dt.timedelta(days = (i+1)*30))\n",
    "for i in range(10):\n",
    "    year = refdate.year + i + 1\n",
    "    month = refdate.month\n",
    "    day = refdate.day\n",
    "    sampling_points_EONIA_dates.append(\n",
    "        dt.datetime(year = year, month = month , day = day)\n",
    "    )\n",
    "#print(sampling_points_EONIA_dates)\n",
    "    \n",
    "# convert to a format the DiscountCurve constructor understands\n",
    "sampling_points_EONIA_PTimes = converter.createPTimeList(refdate, sampling_points_EONIA_dates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# restrict to the columns containing interest rates\n",
    "#data_EONIA_diffs = data_EONIA[data_EONIA.columns[~data_EONIA.columns.isin(['stichtag6','datum'])]]\n",
    "data_EONIA_rates_only = pd.DataFrame(data_EONIA,\n",
    "                       columns = data_EONIA.columns[~data_EONIA.columns.isin(['stichtag6','datum'])]\n",
    "                      )\n",
    "#print(data_EONIA_diffs)\n",
    "\n",
    "# save the current market data in a pandas.series\n",
    "data_EONIA_current = data_EONIA_rates_only.iloc[0,:]\n",
    "#print(data_EONIA_current)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute absolute and relative differences\n",
    "\n",
    "# Copy the data frame structure\n",
    "data_scenarios_absolute = pd.DataFrame().reindex_like(data_EONIA_rates_only)\n",
    "data_scenarios_relative = pd.DataFrame().reindex_like(data_EONIA_rates_only)\n",
    "\n",
    "# Compute the values\n",
    "n = timeinterval\n",
    "# for i in range(len(data_EONIA_rates_only.index) - n):\n",
    "#     for j in range(len(data_EONIA_rates_only.columns)):\n",
    "#         data_scenarios_absolute.iloc[i + n, j] = data_EONIA_current[j] + data_EONIA_rates_only.iloc[i, j] - data_EONIA_rates_only.iloc[i + n, j]\n",
    "#         if data_EONIA_rates_only.iloc[i + n, j] != 0:\n",
    "#             data_scenarios_relative.iloc[i + n, j] = data_EONIA_current[j] * data_EONIA_rates_only.iloc[i, j] / data_EONIA_rates_only.iloc[i + n, j]\n",
    "\n",
    "\n",
    "for i in range(len(data_EONIA_rates_only.index) - n):\n",
    "    for col in data_EONIA_rates_only.columns:\n",
    "        data_scenarios_absolute.iloc[i + n, :][col] = data_EONIA_current[col] + data_EONIA_rates_only.iloc[i, :][col] - data_EONIA_rates_only.iloc[i + n, :][col]\n",
    "        if data_EONIA_rates_only.iloc[i + n, :][col] != 0:\n",
    "            data_scenarios_relative.iloc[i + n, :][col] = data_EONIA_current[col] * data_EONIA_rates_only.iloc[i, :][col] / data_EONIA_rates_only.iloc[i + n, :][col]\n",
    "\n",
    "            \n",
    "# Remove the rows containing NaN (i.e. the first n rows and those where we divided by 0)\n",
    "data_scenarios_absolute = data_scenarios_absolute.dropna()\n",
    "data_scenarios_relative = data_scenarios_relative.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the scenarios as defined at the beginning of this notebook\n",
    "if scenario_construction_type == 'relative':\n",
    "    data_scenarios = data_scenarios_relative\n",
    "if scenario_construction_type == 'absolute':\n",
    "    data_scenarios = data_scenarios_absolute\n",
    "\n",
    "# data_scenarios.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot Scenarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the 'distances' of all scenarios to the current EONIA curve and sort them by that distance\n",
    "\n",
    "# diffs = data_scenarios.copy()\n",
    "# for i in range(len(data_scenarios.index)):\n",
    "#     for j in range(len(data_scenarios.columns)):\n",
    "#         diffs.iloc[i, j] -= data_EONIA_current[j]\n",
    "\n",
    "diffs = data_scenarios - data_EONIA_current\n",
    "distances = [ np.linalg.norm(row) for index, row in diffs.iterrows() ]\n",
    "data_scenarios_with_dist = data_scenarios.copy()\n",
    "#print(data_scenarios_with_dist)\n",
    "data_scenarios_with_dist['dist'] = distances\n",
    "#print(distances)\n",
    "data_scenarios_with_dist.sort_values(by = 'dist', ascending = False, inplace=True)\n",
    "data_scenarios_with_dist = data_scenarios_with_dist.drop('dist', axis=1)\n",
    "data_scenarios_with_dist = data_scenarios_with_dist.reset_index(drop=True)\n",
    "#print(data_scenarios_with_dist)\n",
    "#print(data_scenarios_with_dist.iloc[0:10])\n",
    "\n",
    "# We'll highlight the 'most distant' scenarios in a different color in the plot below\n",
    "indeces_most_distant = data_scenarios_with_dist.index.isin([0,1,2,3])\n",
    "\n",
    "# clean up\n",
    "del diffs\n",
    "del distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup the graph\n",
    "fig = plt.figure(figsize=(16,8))\n",
    "ax = fig.gca()\n",
    "\n",
    "\n",
    "color_current = 'w'\n",
    "color_bulk = 'k'\n",
    "color_maxdist = 'tab:blue'\n",
    "ax.plot(sampling_points_EONIA_yf, data_EONIA_current, '.-', label = 'current EONIA curve', color = color_current, zorder = 20)\n",
    "ax.plot(sampling_points_EONIA_yf, data_scenarios_with_dist[~indeces_most_distant].transpose(), '.-', label = 'other scenarios', color = color_bulk, zorder = 15, alpha=0.05)\n",
    "ax.plot(sampling_points_EONIA_yf, data_scenarios_with_dist[indeces_most_distant].transpose(), '.-', label = 'extreme scenarios', color = color_maxdist, zorder = 15, alpha=1)\n",
    "#ax.plot(samplingPoints, data_scenarios_with_dist.iloc[0], '.-', label = 'EONIA rate', color = color_maxdist, zorder = 20, alpha=1)\n",
    "#ax.plot(samplingPoints, data_scenarios_with_dist.iloc[4], '.-', label = 'EONIA rate', color = color_maxdist, zorder = 20, alpha=1)\n",
    "#ax.plot(samplingPoints, data_scenarios_with_dist.iloc[5], '.-', label = 'EONIA rate', color = color_maxdist, zorder = 20, alpha=1)\n",
    "\n",
    "\n",
    "plt.xlabel('Expiry (in years)')\n",
    "plt.ylabel('Interest rate (in base points)')\n",
    "ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "\n",
    "\n",
    "legend_elements = [\n",
    "    Patch(facecolor=color_current, edgecolor='gainsboro', label='current EONIA curve'),\n",
    "    Patch(facecolor=color_maxdist, label='extreme scenarios'),\n",
    "    Patch(facecolor=color_bulk, label='other scenarios')\n",
    "]\n",
    "plt.legend(handles=legend_elements, loc='lower right')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(data_scenarios.min())\n",
    "# print(data_scenarios.idxmin())\n",
    "# print(data_scenarios.min().min())\n",
    "# print(data_scenarios.min().idxmin())\n",
    "# print(imin)\n",
    "\n",
    "imin = data_scenarios.idxmin()[data_scenarios.min().idxmin()]\n",
    "imax = data_scenarios.idxmax()[data_scenarios.max().idxmax()]\n",
    "\n",
    "pd.DataFrame({\n",
    "    'Current': data_EONIA_current,\n",
    "    'imin': data_EONIA_rates_only.loc[imin,:],\n",
    "    'imin - n': data_EONIA_rates_only.loc[imin - timeinterval,:],\n",
    "    'Scenario (imin)': data_scenarios.loc[imin,:],\n",
    "    'imax': data_EONIA_rates_only.loc[imax,:],\n",
    "    'imax - n': data_EONIA_rates_only.loc[imax - timeinterval,:],\n",
    "    'Scenario (imax)': data_scenarios.loc[imax,:]\n",
    "}).head(len(data_EONIA_current))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define a Portfolio\n",
    "Start with one simple bond."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "duration = 10\n",
    "maturity = dt.datetime(year = refdate.year + duration, month = refdate.month, day = refdate.day)\n",
    "#print(refdate)\n",
    "#print(maturity)\n",
    "\n",
    "# Generate the coupon payment schedule as a vector of datetimes\n",
    "coupon_dates = []\n",
    "for i in range(duration):\n",
    "    coupon_dates.append(dt.datetime(year = refdate.year + i + 1, month = refdate.month, day = refdate.day))\n",
    "#print(coupon_dates)\n",
    "\n",
    "# We now use these dates to define a fixed coupon bond\n",
    "principal = 100.0\n",
    "coupon_rate = 0.05\n",
    "coupon_rates = [coupon_rate]*len(coupon_dates)\n",
    "coupon_payments = [coupon_rate*principal]*len(coupon_dates)\n",
    "\n",
    "fixed_coupon_bond = pyvacon.instruments.BondSpecification('Fixed_Coupon', 'DBK', enums.SecuritizationLevel.NONE, 'EUR',\n",
    "    maturity, refdate, principal, daycounter_type_standard, coupon_dates, coupon_rates, '', [], [])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute the Credit Spread and Portfolio Values\n",
    "First, we make some preparations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the pricer, we're going to use to price our bond\n",
    "pricing_data_simple = pyvacon.pricing.BondPricingData()\n",
    "pricing_data_simple.param = pyvacon.pricing.BondPricingParameter()\n",
    "pricing_data_simple.param.useJLT = False\n",
    "pricing_data_simple.pricingRequest = pyvacon.pricing.PricingRequest()\n",
    "pricing_data_simple.pricingRequest.setCleanPrice(True)\n",
    "pricing_data_simple.pricer = 'BondPricer'\n",
    "pricing_data_simple.spec = fixed_coupon_bond"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We want to compute the value of our portfolio after the timeinterval (in days) defined above\n",
    "valdate = refdate + dt.timedelta(days = timeinterval)\n",
    "pricing_data_simple.valDate = valdate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute Credit Spread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the current EONIA rates + a constant rate to compute the price of the fixed coupon bond\n",
    "# Vary the constant rate and repeat until the value of the bond is right about the same as its principal\n",
    "creditspread = coupon_rate * 100 # in base points\n",
    "stepsize = coupon_rate * 100 # the initial step size used to vary the interest rate\n",
    "spreads = []\n",
    "values = []\n",
    "for k in range(20):\n",
    "    # create DC defined by the scenario\n",
    "    dsc_fac = analytics.vectorDouble()\n",
    "    spreadScenario = data_EONIA_current + creditspread;\n",
    "    for i in range(len(spreadScenario)):\n",
    "        dsc_fac.append(math.exp(-spreadScenario.iloc[i]/100*i)) # t = i years  # market data is given in base points -> /100  \n",
    "            \n",
    "    discountCurve = analytics.DiscountCurve('dc_linear', refdate, sampling_points_EONIA_dates, dsc_fac, enums.DayCounter.ACTACT, enums.InterpolationType.LINEAR, enums.ExtrapolationType.NONE)\n",
    "    pricing_data_simple.discountCurve = discountCurve\n",
    "    \n",
    "    results = pyvacon.pricing.price(pricing_data_simple)\n",
    "    \n",
    "    values.append(results.getPrice())\n",
    "    spreads.append(creditspread)\n",
    "    \n",
    "    if values[k] > principal:\n",
    "        creditspread += stepsize\n",
    "    else:\n",
    "        creditspread -= stepsize\n",
    "    stepsize /= 2\n",
    "\n",
    "#print(spreads)\n",
    "#print(values)\n",
    "print(creditspread)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute Portfolio Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the price of the fixed coupon bond at the valuation date defined above\n",
    "# Repeat for every scenario\n",
    "results_dirty = []\n",
    "results_clean = []\n",
    "for index, scenario in data_scenarios.iterrows():\n",
    "    # add the credit spread we computed for our bond\n",
    "    scenario = scenario + creditspread\n",
    "    \n",
    "    # create DC defined by the scenario\n",
    "    dsc_fac = analytics.vectorDouble()\n",
    "    for i in range(len(scenario)):\n",
    "            dsc_fac.append(math.exp(-scenario.iloc[i]/100*i)) # t = i years  # market data is given in base points -> /100  \n",
    "            \n",
    "    discountCurve = analytics.DiscountCurve('dc_linear', refdate, sampling_points_EONIA_dates, dsc_fac, daycounter_type_standard, interpolation_type_standard, extrapolation_type_standard)\n",
    "    pricing_data_simple.discountCurve = discountCurve\n",
    "    \n",
    "    results = pyvacon.pricing.price(pricing_data_simple)\n",
    "    results_dirty.append(results.getPrice())\n",
    "    results_clean.append(results.getCleanPrice())\n",
    "    #print(pricing_data_simple.spec.getObjectId() + ', dirty price: ' + str(results.getPrice()) + \",  clean price: \" + str(results.getCleanPrice()))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(scenario)\n",
    "#print(scenario.to_numpy())\n",
    "#print(results_dirty)\n",
    "#print(results_clean)\n",
    "\n",
    "minIndex = results_dirty.index(min(results_dirty))\n",
    "#print(minIndex)\n",
    "#print(results_clean.index(min(results_clean)))\n",
    "print(results_dirty[minIndex])\n",
    "#print(results_clean[minIndex])\n",
    "#print(data_scenarios.iloc[minIndex])\n",
    "\n",
    "\n",
    "maxIndex = results_dirty.index(max(results_dirty))\n",
    "#print(maxIndex)\n",
    "#print(results_clean.index(max(results_clean)))\n",
    "print(results_dirty[maxIndex])\n",
    "#print(results_clean[maxIndex])\n",
    "#print(data_scenarios.iloc[maxIndex])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute the current value\n",
    "\n",
    "\n",
    "# create DC defined by the scenario\n",
    "dsc_fac = analytics.vectorDouble()\n",
    "for i in range(len(scenario)):\n",
    "        dsc_fac.append(math.exp(-(data_EONIA_current + creditspread).iloc[i]/100*i)) # t = i years  # market data is given in base points -> /100  \n",
    "\n",
    "discountCurve = analytics.DiscountCurve('dc_linear', refdate, sampling_points_EONIA_dates, dsc_fac, daycounter_type_standard, interpolation_type_standard, extrapolation_type_standard)\n",
    "pricing_data_simple.discountCurve = discountCurve\n",
    "results = pyvacon.pricing.price(pricing_data_simple)\n",
    "currentPriceDirty = results.getPrice()\n",
    "currentPriceClean = results.getCleanPrice()\n",
    "print(currentPriceDirty)\n",
    "#print(currentPriceClean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot pricing results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_dirty = np.sort(results_dirty)\n",
    "#results_clean = np.sort(results_clean)\n",
    "\n",
    "# Histogramm\n",
    "# Setup the graph\n",
    "fig_values = plt.figure(figsize=(16,8))\n",
    "ax = fig_values.gca()\n",
    "#bx = ax.twinx()\n",
    "\n",
    "ax.hist(results_dirty, bins=60, color = color_main, zorder = 20, edgecolor='w')\n",
    "ax.axvline(x=currentPriceDirty, ymin=0, ymax=1, color=color_highlight, zorder = 30)\n",
    "\n",
    "plt.xlabel('Portfolio value')\n",
    "plt.ylabel('Number of occurences')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histogramm of the changes/differences in value\n",
    "valDiffsDirty = np.asarray([res - currentPriceDirty for res in results_dirty])\n",
    "fig_diff = plt.figure(figsize=(16,8))\n",
    "ax = fig_diff.gca()\n",
    "\n",
    "#ax.plot(valdates, results_dirtyFCB, '.', label = 'Dirty Price', color = colorPrice, zorder = 20)\n",
    "ax.hist(valDiffsDirty, bins=60, color=color_main, zorder = 20, edgecolor='w')\n",
    "ax.axvline(x=0, ymin=0, ymax=1, color=color_highlight, zorder = 30)\n",
    "\n",
    "plt.xlabel('Change in portfolio value')\n",
    "plt.ylabel('Number of occurences')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute Value at Risk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valDiffsDirty = (-1)*np.sort((-1)*valDiffsDirty)\n",
    "quantile = 0.99\n",
    "#print(np.quantile(valDiffsDirty, 1-quantile, interpolation='higher')) # apparently always uses ascending order\n",
    "\n",
    "# Compute the number of the entry corresponding to the quantile defined above\n",
    "quantileIndex = np.ceil(len(valDiffsDirty)*quantile).astype(int)\n",
    "#print(quantileIndex)\n",
    "#print(quantile * len(valDiffsDirty))\n",
    "\n",
    "# To get the index of this entry, we have to subtract 1\n",
    "quantileIndex -= 1\n",
    "\n",
    "print('With a probability of ' + ((quantileIndex + 1)/len(valDiffsDirty)*100).astype('str') + '%')\n",
    "print('the value of our portfolio is not going to shrink by more than ' + (-1 * valDiffsDirty[quantileIndex]).astype('str'))\n",
    "print('in the next ' + str(timeinterval) + ' day(s)')\n",
    "\n",
    "# Check correctness\n",
    "#print('--------------')\n",
    "#print(valDiffsDirty[quantileIndex-1])\n",
    "#print((quantileIndex)/len(valDiffsDirty))\n",
    "#print('--------------')\n",
    "#print(valDiffsDirty[quantileIndex])\n",
    "#print((quantileIndex + 1)/len(valDiffsDirty))\n",
    "#print('--------------')\n",
    "#print(valDiffsDirty[quantileIndex+1])\n",
    "#print((quantileIndex + 2)/len(valDiffsDirty))\n",
    "#print('--------------')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot cummulative relative frequencies of loss of portfolio value\n",
    "fig_diff = plt.figure(figsize=(16,8))\n",
    "ax = fig_diff.gca()\n",
    "\n",
    "losses = -valDiffsDirty\n",
    "losses = np.sort(losses)\n",
    "\n",
    "# choose bins in a way which maximizes the resolution of the histogramm\n",
    "bins = np.unique(losses)\n",
    "bins = np.append(bins, losses[len(losses)-1] + 0.00001 )\n",
    "\n",
    "# 'density = True' produces relative frequencies instead of absolute numbers of occurences\n",
    "ax.hist(losses, bins=bins, color = color_main, cumulative = True, density = True, zorder = 20)\n",
    "\n",
    "# draw lines to highlight the quantile\n",
    "vlineAt = -valDiffsDirty[quantileIndex];\n",
    "hline = ax.axhline(y=quantile, xmin=0, xmax=1, color=color_highlight, linewidth=1, zorder = 30)\n",
    "vline = ax.axvline(x=vlineAt, ymin=0, ymax=1, color=color_highlight, linewidth=1, zorder = 30)\n",
    "\n",
    "# clip the lines\n",
    "eps = 0.1\n",
    "xmin = ax.get_xlim()[0];\n",
    "ymin = ax.get_ylim()[0];\n",
    "hrect = Rectangle((xmin, quantile - eps), abs(xmin) + vlineAt, 2*eps, facecolor=\"none\", edgecolor=\"none\")\n",
    "vrect = Rectangle((vlineAt - eps, ymin), 2*eps, abs(ymin) + quantile, facecolor=\"none\", edgecolor=\"none\")\n",
    "\n",
    "ax.add_artist(hrect)\n",
    "ax.add_artist(vrect)\n",
    "hline.set_clip_path(hrect)\n",
    "vline.set_clip_path(vrect)\n",
    "\n",
    "# TODO: weiter dran arbeiten\n",
    "\n",
    "\n",
    "plt.xlabel('Loss of portfolio value')\n",
    "plt.ylabel('Cumulative relative frequency')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add a swap to our portfolio\n",
    "We swap the fixed coupon payments for an interest rate of EONIA plus the credit spread we computed earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the swap scpecification\n",
    "startdates = [refdate]\n",
    "startdates.extend(coupon_dates[0:len(coupon_dates)-1])\n",
    "#startdates = converter.createPTimeList(refdate, startdates)\n",
    "\n",
    "enddates = coupon_dates\n",
    "#enddates = converter.createPTimeList(enddates, startdates)\n",
    "\n",
    "#print(startdates)\n",
    "#print(enddates)\n",
    "\n",
    "paydates = enddates\n",
    "resetdates = startdates\n",
    "\n",
    "notionals = analytics.vectorDouble()\n",
    "notionals.append(principal)\n",
    "\n",
    "fixedleg = analytics.IrFixedLegSpecification(coupon_rate, notionals, startdates, enddates, paydates,'EUR', daycounter_type_standard)\n",
    "\n",
    "floatleg = analytics.IrFloatLegSpecification(notionals, resetdates, startdates, enddates,\n",
    "                                    paydates,'EUR', 'test_udl', daycounter_type_standard, \n",
    "                                    0)\n",
    "                                    #creditspread/100) # spread is given in basepoints\n",
    "\n",
    "ir_swap = analytics.InterestRateSwapSpecification('TEST_SWAP', 'DBK', enums.SecuritizationLevel.COLLATERALIZED, 'EUR',\n",
    "                                           converter.getLTime(paydates[-1]), fixedleg, floatleg)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recompute the value of our portfolio in all scenarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify all data we need to price the swap\n",
    "ir_swap_pricing_data = analytics.InterestRateSwapPricingData()\n",
    "\n",
    "pay_leg_pricing_data = analytics.InterestRateSwapLegPricingData()\n",
    "pay_leg_pricing_data.spec = ir_swap.getPayLeg()\n",
    "pay_leg_pricing_data.fxRate = 1.0\n",
    "pay_leg_pricing_data.weight = -1.0\n",
    "\n",
    "rec_leg_pricing_data = analytics.InterestRateSwapFloatLegPricingData()\n",
    "rec_leg_pricing_data.spec = ir_swap.getReceiveLeg()\n",
    "rec_leg_pricing_data.fxRate = 1.0\n",
    "rec_leg_pricing_data.weight = 1.0\n",
    "\n",
    "ir_swap_pricing_data.pricer = 'InterestRateSwapPricer'\n",
    "ir_swap_pricing_data.pricingRequest = analytics.PricingRequest()\n",
    "ir_swap_pricing_data.valDate = converter.getLTime(refdate)\n",
    "ir_swap_pricing_data.setCurr('EUR')\n",
    "ir_swap_pricing_data.addLegData(pay_leg_pricing_data)\n",
    "ir_swap_pricing_data.addLegData(rec_leg_pricing_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the price of our portfolio\n",
    "# Repeat for every scenario\n",
    "results_dirty = []\n",
    "results_clean = []\n",
    "for index, scenario in data_scenarios.iterrows():\n",
    "    # add the credit spread we computed for our bond\n",
    "    \n",
    "    # create DC defined by the scenario\n",
    "    factorsEONIA = analytics.vectorDouble()\n",
    "    factorsWithSpread = analytics.vectorDouble()\n",
    "    for i in range(len(scenario)):\n",
    "        factorsEONIA.append(math.exp(-scenario.iloc[i]/100*i)) # t = i years  # market data is given in base points -> /100  \n",
    "        factorsWithSpread.append(math.exp(-(scenario.iloc[i] + creditspread)/100*i)) # t = i years  # market data is given in base points -> /100  \n",
    "            \n",
    "    dcEONIA = analytics.DiscountCurve('dc_linear', refdate, sampling_points_EONIA_dates, factorsEONIA, daycounter_type_standard, interpolation_type_standard, extrapolation_type_standard)\n",
    "    dcWithSpread   = analytics.DiscountCurve('dc_linear_spread', refdate, sampling_points_EONIA_dates, factorsWithSpread, daycounter_type_standard, interpolation_type_standard, extrapolation_type_standard)\n",
    "    \n",
    "    pricing_data_simple.discountCurve = dcEONIA # dcWithSpread\n",
    "    pay_leg_pricing_data.discountCurve = dcEONIA\n",
    "    rec_leg_pricing_data.discountCurve = dcEONIA\n",
    "    rec_leg_pricing_data.fixingCurve = dcEONIA\n",
    "    \n",
    "    prBond = pyvacon.pricing.price(pricing_data_simple)\n",
    "    prSwap = analytics.price(ir_swap_pricing_data)\n",
    "    dirty = prBond.getPrice() + prSwap.getPrice()\n",
    "    clean = prBond.getCleanPrice() + prSwap.getCleanPrice()\n",
    "    results_dirty.append(dirty)\n",
    "    results_clean.append(clean)\n",
    "    #print(pricing_data_simple.spec.getObjectId() + ', dirty price: ' + str(results.getPrice()) + \",  clean price: \" + str(results.getCleanPrice()))\n",
    "#print(results_dirty)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#analytics.setLogLevel('DEBUG')\n",
    "#tic = dt.datetime.now()\n",
    "#pr = analytics.price(ir_swap_pricing_data)\n",
    "#print('runtime: {}'.format(dt.datetime.now() - tic))\n",
    "#pr.getPrice()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute the current value as a reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a discount curve based on the current EONIA rates\n",
    "factorsEONIA = analytics.vectorDouble()\n",
    "factorsWithSpread = analytics.vectorDouble()\n",
    "for i in range(len(data_EONIA_current)):\n",
    "    factorsEONIA.append(math.exp(-data_EONIA_current.iloc[i]/100*i)) # t = i years  # market data is given in base points -> /100  \n",
    "    factorsWithSpread.append(math.exp(-(data_EONIA_current.iloc[i] + creditspread)/100*i)) # t = i years  # market data is given in base points -> /100  \n",
    "    \n",
    "dcEONIA = analytics.DiscountCurve('dc_linear', refdate, sampling_points_EONIA_dates, factorsEONIA, daycounter_type_standard, interpolation_type_standard, extrapolation_type_standard)\n",
    "dcWithSpread = analytics.DiscountCurve('dc_linear_spread', refdate, sampling_points_EONIA_dates, factorsWithSpread, daycounter_type_standard, interpolation_type_standard, extrapolation_type_standard)\n",
    "\n",
    "pricing_data_simple.discountCurve = dcEONIA # dcWithSpread\n",
    "pay_leg_pricing_data.discountCurve = dcEONIA\n",
    "rec_leg_pricing_data.discountCurve = dcEONIA \n",
    "rec_leg_pricing_data.fixingCurve = dcEONIA\n",
    "\n",
    "# compute portfolio value\n",
    "prBond = pyvacon.pricing.price(pricing_data_simple)\n",
    "prSwap = analytics.price(ir_swap_pricing_data)\n",
    "#print(prSwap.getPrice())\n",
    "#print(prBond.getPrice())\n",
    "currentValueBond = prBond.getPrice()\n",
    "currentValueSwap = prSwap.getPrice()\n",
    "currentValue = prBond.getPrice() + prSwap.getPrice()\n",
    "print(currentValueSwap)\n",
    "print(currentValueBond)\n",
    "print(currentValue)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the pricing results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histogramm of the changes/differences in value\n",
    "valDiffsDirty = np.asarray([res - currentValue for res in results_dirty])\n",
    "fig_diff = plt.figure(figsize=(16,8))\n",
    "ax = fig_diff.gca()\n",
    "\n",
    "#ax.plot(valdates, results_dirtyFCB, '.', label = 'Dirty Price', color = colorPrice, zorder = 20)\n",
    "ax.hist(valDiffsDirty, bins=60, color = color_main, zorder = 20, edgecolor='w')\n",
    "#ax.axvline(x=0, ymin=0, ymax=1, color=color_highlight, zorder = 30)\n",
    "\n",
    "plt.xlabel('Change in portfolio value')\n",
    "plt.ylabel('Number of occurences')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interest Rate Shock Scenarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define functions to help compute the shock scenarios\n",
    "\n",
    "def shortRateShock(t, basepoints):\n",
    "    if isinstance(t, (list, np.ndarray)):\n",
    "        result = []\n",
    "        for x in t:\n",
    "            result.append(shortRateShock(x, basepoints))\n",
    "        #print('list')\n",
    "        return result\n",
    "    #print('scalar')\n",
    "    #print(type(t))\n",
    "    return np.exp(-t/4) * basepoints\n",
    "\n",
    "\n",
    "def longRateShock(t, basepoints):\n",
    "    if isinstance(t, (list, np.ndarray)):\n",
    "        result = []\n",
    "        for x in t:\n",
    "            result.append(longRateShock(x, basepoints))\n",
    "        return result\n",
    "    return (1-math.exp(-t/4)) * basepoints\n",
    "\n",
    "\n",
    "def steepener(t, basepointsShort, basepointsLong):\n",
    "    if isinstance(t, (list, np.ndarray)):\n",
    "        result = []\n",
    "        for x in t:\n",
    "            result.append(steepener(x, basepointsShort, basepointsLong))\n",
    "        return result\n",
    "    return -0.65 * shortRateShock(t, basepointsShort)  +  0.9 * longRateShock(t, basepointsLong)\n",
    "\n",
    "\n",
    "def flattener(t, basepointsShort, basepointsLong):\n",
    "    if isinstance(t, (list, np.ndarray)):\n",
    "        result = []\n",
    "        for x in t:\n",
    "            result.append(flattener(x, basepointsShort, basepointsLong))\n",
    "        return result\n",
    "    return 0.8 * shortRateShock(t, basepointsShort)  -  0.6 * longRateShock(t, basepointsLong)\n",
    "\n",
    "\n",
    "def getShockValue(t, shockScenario, parallel = 0, short = 0, long = 0):\n",
    "    \n",
    "    if shockScenario == 'Parallel':\n",
    "        return parallel\n",
    "    \n",
    "    if shockScenario == 'ParallelUp':\n",
    "        return parallel\n",
    "    \n",
    "    if shockScenario == 'ParallelDown':\n",
    "        return -parallel\n",
    "    \n",
    "    \n",
    "    \n",
    "    if shockScenario == 'Short':\n",
    "        return shortRateShock(t, short)\n",
    "    \n",
    "    if shockScenario == 'ShortUp':\n",
    "        return shortRateShock(t, short)\n",
    "    \n",
    "    if shockScenario == 'ShortDown':\n",
    "        return shortRateShock(t, -short)\n",
    "    \n",
    "    \n",
    "    \n",
    "    if shockScenario == 'Long':\n",
    "        return longRateShock(t, long)\n",
    "    \n",
    "    if shockScenario == 'LongUp':\n",
    "        return longRateShock(t, long)\n",
    "    \n",
    "    if shockScenario == 'LongDown':\n",
    "        return longRateShock(t, -long)\n",
    "    \n",
    "    \n",
    "    \n",
    "    if shockScenario == 'Flatten':\n",
    "        return flattener(t, short, long)\n",
    "    \n",
    "    if shockScenario == 'Steepen':\n",
    "        return steepener(t, short, long)\n",
    "    \n",
    "    \n",
    "    raise InvalidArgument('I don\\'t know a scenario of the name \\'' + shockScenario + '\\'')\n",
    "\n",
    "\n",
    "\n",
    "# define the parameters for the shock scenarios\n",
    "\n",
    "shockParams = pd.DataFrame({'Currency': [], 'Parallel': [], 'Short': [], 'Long': []})\n",
    "shockParams = shockParams.append({'Currency': 'EUR', 'Parallel': 200, 'Short': 250, 'Long': 100}, ignore_index = True)\n",
    "shockParams = shockParams.append({'Currency': 'GBP', 'Parallel': 250, 'Short': 300, 'Long': 150}, ignore_index = True)\n",
    "shockParams = shockParams.append({'Currency': 'USD', 'Parallel': 200, 'Short': 300, 'Long': 150}, ignore_index = True)\n",
    "\n",
    "    \n",
    "########################################################################################################### \n",
    "\n",
    "\n",
    "def getShockedInterestRates(\n",
    "        refdate,\n",
    "        dates,\n",
    "        interestRates,\n",
    "        daycounter,\n",
    "        shockScenario,\n",
    "        parallel = 0,\n",
    "        short = 0,\n",
    "        long = 0):\n",
    "    if len(interestRates) != len(dates):\n",
    "        raise RangeMismatch('You need to provide an equal number of discount factors and sampling dates.')\n",
    "    \n",
    "    shockedInterestRates = []\n",
    "    \n",
    "    for i in range(len(dates)):\n",
    "        t = daycounter.yf(refdate, dates[i])\n",
    "        rate = interestRates[i] + getShockValue(t, shockScenario, parallel, short, long)\n",
    "        shockedInterestRates.append(rate)\n",
    "    \n",
    "    #print(shockedInterestRates)\n",
    "    \n",
    "    return shockedInterestRates\n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "# Define a function, which shifts a discount curve according to the shock scenarios\n",
    "# We start by defining a function, which shifts a vector of discount factors\n",
    "\n",
    "def getShockedDiscountFactors(\n",
    "        refdate,\n",
    "        dates,\n",
    "        interestRates,\n",
    "        daycounter,\n",
    "        shockScenario,\n",
    "        parallel = 0,\n",
    "        short = 0,\n",
    "        long = 0):\n",
    "    \n",
    "    if len(interestRates) != len(dates):\n",
    "        raise RangeMismatch('You need to provide an equal number of discount factors and sampling dates.')\n",
    "    \n",
    "    shockedInteresRates = getShockedInterestRates(\n",
    "        refdate,\n",
    "        dates,\n",
    "        interestRates,\n",
    "        daycounter,\n",
    "        shockScenario,\n",
    "        parallel,\n",
    "        short,\n",
    "        long\n",
    "    )    \n",
    "    \n",
    "    shockedDiscountFactors = []\n",
    "    #shockedDiscountFactors = analytics.vectorDouble(len(dates))\n",
    "    #print(shockedDiscountFactors)\n",
    "    \n",
    "    for i in range(len(dates)):\n",
    "        t = daycounter.yf(refdate, dates[i])\n",
    "        rate = shockedInteresRates[i]/100 # are given in percent -> convert to decimal number\n",
    "        shockedDiscountFactors.append(math.exp(-t*rate))\n",
    "        #shockedDiscountFactors[i] = discountFactors[i] + getShockValue(t, shockScenario, parallel, short, long)\n",
    "        #print(shockedDiscountFactors)\n",
    "    \n",
    "    #print(\"//////////////////////////////////////////////\")\n",
    "    #print(shockedInteresRates)\n",
    "    #print(\"-----------------------\")\n",
    "    #print(shockedDiscountFactors)\n",
    "    #print(\"//////////////////////////////////////////////\")\n",
    "    \n",
    "    return shockedDiscountFactors\n",
    "    \n",
    "    \n",
    "    \n",
    "# We now use these shifted discount factors to construct shifted discount curves     \n",
    "    \n",
    "\n",
    "def getShockedDiscountCurve(\n",
    "        name,\n",
    "        refdate,\n",
    "        dates,\n",
    "        interestRates,\n",
    "        daycounterType,\n",
    "        interpolationType,\n",
    "        extrapolationType,\n",
    "        shockScenario,\n",
    "        parallel = 0,\n",
    "        short = 0,\n",
    "        long = 0):\n",
    "    \n",
    "    shockedDFs = getShockedDiscountFactors(\n",
    "        refdate,\n",
    "        dates,\n",
    "        interestRates,\n",
    "        analytics.DayCounter(daycounterType),\n",
    "        shockScenario,\n",
    "        parallel,\n",
    "        short,\n",
    "        long\n",
    "    )    \n",
    "    \n",
    "    #print(shockedDFs)\n",
    "    \n",
    "    return analytics.DiscountCurve(\n",
    "        name,\n",
    "        refdate,\n",
    "        dates,\n",
    "        shockedDFs,\n",
    "        daycounterType,\n",
    "        interpolationType,\n",
    "        extrapolationType\n",
    "    )\n",
    "\n",
    "###########################################################################################################    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The scenarios\n",
    "### Plot the shock scenarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_shock_scenarios(\n",
    "    samplingPoints,\n",
    "    shockParams\n",
    "):\n",
    "    fig = plt.figure(figsize=(16,8))\n",
    "    ax = fig.gca()\n",
    "\n",
    "    currency = 'EUR'\n",
    "    parallel = shockParams.loc[shockParams['Currency'] == currency].loc[0]['Parallel']\n",
    "    short = shockParams.loc[shockParams['Currency'] == currency].loc[0]['Short']\n",
    "    long = shockParams.loc[shockParams['Currency'] == currency].loc[0]['Long']\n",
    "\n",
    "    #print(type(samplingPoints))\n",
    "\n",
    "    #print(shortRateShock(short, samplingPoints))\n",
    "    hline = ax.axhline(y=0, xmin=0, xmax=1, linewidth=1, zorder = 30)\n",
    "    ax.plot(samplingPoints, [parallel]*len(samplingPoints), '.-', label = 'ParallelUp', zorder = 20)\n",
    "    ax.plot(samplingPoints, [-parallel]*len(samplingPoints), '.-', label = 'ParallelDown', zorder = 20)\n",
    "    ax.plot(samplingPoints, shortRateShock(samplingPoints, short), '.-', label = 'ShortUp', zorder = 20)\n",
    "    ax.plot(samplingPoints, shortRateShock(samplingPoints, -short), '.-', label = 'ShortDown', zorder = 20)\n",
    "    ax.plot(samplingPoints, longRateShock(samplingPoints, long), '.-', label = 'LongUp', zorder = 20)\n",
    "    ax.plot(samplingPoints, longRateShock(samplingPoints, -long), '.-', label = 'LongDown', zorder = 20)\n",
    "    ax.plot(samplingPoints, flattener(samplingPoints, short, long), '.-', label = 'Flattener', zorder = 20)\n",
    "    ax.plot(samplingPoints, steepener(samplingPoints, short, long), '.-', label = 'Steepener', zorder = 20)\n",
    "\n",
    "\n",
    "    plt.grid(alpha=grid_alpha) \n",
    "    plt.xlabel('Expiry (in years)')\n",
    "    plt.ylabel('Interest rate (in base points)')\n",
    "    ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "\n",
    "    plt.legend(loc='lower right').set_zorder(100)\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "plot_shock_scenarios(sampling_points_EONIA_yf, shockParams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_shocked_interest_rates(\n",
    "    refdate,\n",
    "    dates,\n",
    "    interestRates,\n",
    "    daycounter\n",
    "):\n",
    "    fig = plt.figure(figsize=(16,8))\n",
    "    ax = fig.gca()\n",
    "\n",
    "    currency = 'EUR'\n",
    "    parallel = shockParams.loc[shockParams['Currency'] == currency].loc[0]['Parallel']\n",
    "    short = shockParams.loc[shockParams['Currency'] == currency].loc[0]['Short']\n",
    "    long = shockParams.loc[shockParams['Currency'] == currency].loc[0]['Long']\n",
    "\n",
    "    #print(type(samplingPoints))\n",
    "\n",
    "    #print(shortRateShock(short, samplingPoints))\n",
    "    hline = ax.axhline(y=0, xmin=0, xmax=1, linewidth=1, zorder = 30)\n",
    "    shockScenarios = ['ParallelUp', 'ParallelDown', 'ShortUp', 'ShortDown', 'LongUp', 'LongDown', 'Flatten', 'Steepen']\n",
    "    for shockScenario in shockScenarios:\n",
    "        ir = getShockedInterestRates(\n",
    "            refdate,\n",
    "            dates,\n",
    "            interestRates,\n",
    "            daycounter,\n",
    "            shockScenario,\n",
    "            parallel,\n",
    "            short,\n",
    "            long\n",
    "        )\n",
    "        year_fractions = []\n",
    "        for i in range(len(dates)):\n",
    "            year_fractions.append(daycounter.yf(refdate, dates[i]))\n",
    "        \n",
    "        ax.plot(year_fractions, ir, '.-', label = shockScenario, zorder = 20)\n",
    "\n",
    "    \n",
    "    plt.grid(alpha=grid_alpha)    \n",
    "    plt.xlabel('Expiry (in years)')\n",
    "    plt.ylabel('Interest rate (in base points)')\n",
    "    ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "\n",
    "    plt.legend(loc='lower right').set_zorder(100)\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "interestRates = [0] * len(sampling_points_EONIA_dates)\n",
    "\n",
    "plot_shocked_interest_rates(\n",
    "    refdate,\n",
    "    sampling_points_EONIA_dates,\n",
    "    interestRates,\n",
    "    analytics.DayCounter(daycounter_type_standard)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the shock scenarios (discount factors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_shocked_discount_factors(\n",
    "    refdate,\n",
    "    dates,\n",
    "    interestRates,\n",
    "    daycounter\n",
    "):\n",
    "    fig = plt.figure(figsize=(16,8))\n",
    "    ax = fig.gca()\n",
    "\n",
    "    currency = 'EUR'\n",
    "    parallel = shockParams.loc[shockParams['Currency'] == currency].loc[0]['Parallel']\n",
    "    short = shockParams.loc[shockParams['Currency'] == currency].loc[0]['Short']\n",
    "    long = shockParams.loc[shockParams['Currency'] == currency].loc[0]['Long']\n",
    "\n",
    "    #print(type(samplingPoints))\n",
    "\n",
    "    #print(shortRateShock(short, samplingPoints))\n",
    "    hline = ax.axhline(y=1, xmin=0, xmax=1, linewidth=1, zorder = 30)\n",
    "    shockScenarios = ['ParallelUp', 'ParallelDown', 'ShortUp', 'ShortDown', 'LongUp', 'LongDown', 'Flatten', 'Steepen']\n",
    "    for shockScenario in shockScenarios:\n",
    "        df = getShockedDiscountFactors(\n",
    "            refdate,\n",
    "            dates,\n",
    "            interestRates,\n",
    "            daycounter,\n",
    "            shockScenario,\n",
    "            parallel/100,\n",
    "            short/100,\n",
    "            long/100\n",
    "        )\n",
    "        year_fractions = []\n",
    "        for i in range(len(dates)):\n",
    "            year_fractions.append(daycounter.yf(refdate, dates[i]))\n",
    "        \n",
    "        ax.plot(year_fractions, df, '.-', label = shockScenario, zorder = 20)\n",
    "\n",
    "    \n",
    "    plt.grid(alpha=grid_alpha) \n",
    "    plt.xlabel('Expiry (in years)')\n",
    "    plt.ylabel('Discount factor')\n",
    "    ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "\n",
    "    plt.legend(loc='lower right').set_zorder(100)\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "interestRates = [0] * len(sampling_points_EONIA_dates)\n",
    "\n",
    "plot_shocked_discount_factors(\n",
    "    refdate,\n",
    "    sampling_points_EONIA_dates,\n",
    "    interestRates,\n",
    "    analytics.DayCounter(daycounter_type_standard)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot them again, using discount curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_shocked_discount_curves(\n",
    "    name,\n",
    "    refdate,\n",
    "    dates,\n",
    "    discountFactors,\n",
    "    daycounterType,\n",
    "    interpolationType,\n",
    "    extrapolationType,\n",
    "    shockParams\n",
    "):\n",
    "    fig = plt.figure(figsize=(16,8))\n",
    "    ax = fig.gca()\n",
    "\n",
    "    currency = 'EUR'\n",
    "    parallel = shockParams.loc[shockParams['Currency'] == currency].loc[0]['Parallel']\n",
    "    short = shockParams.loc[shockParams['Currency'] == currency].loc[0]['Short']\n",
    "    long = shockParams.loc[shockParams['Currency'] == currency].loc[0]['Long']\n",
    "    \n",
    "    daycounter = analytics.DayCounter(daycounterType)\n",
    "\n",
    "    #print(type(samplingPoints))\n",
    "\n",
    "    #print(shortRateShock(short, samplingPoints))\n",
    "    hline = ax.axhline(y=1, xmin=0, xmax=1, linewidth=1, zorder = 30)\n",
    "    shockScenarios = ['ParallelUp', 'ParallelDown', 'ShortUp', 'ShortDown', 'LongUp', 'LongDown', 'Flatten', 'Steepen']\n",
    "    for shockScenario in shockScenarios:\n",
    "        dc = getShockedDiscountCurve(\n",
    "            name + '_' + shockScenario,\n",
    "            refdate,\n",
    "            dates,\n",
    "            discountFactors,\n",
    "            daycounterType,\n",
    "            interpolationType,\n",
    "            extrapolationType,\n",
    "            shockScenario,\n",
    "            parallel/100,\n",
    "            short/100,\n",
    "            long/100\n",
    "        )\n",
    "        \n",
    "        year_fractions = []\n",
    "        for i in range(len(dates)):\n",
    "            year_fractions.append(daycounter.yf(refdate, dates[i]))\n",
    "        values = analytics.vectorDouble()\n",
    "        dc.value(values, refdate, dates)\n",
    "            \n",
    "        ax.plot(year_fractions, values, '.-', label = shockScenario, zorder = 20)\n",
    "\n",
    "        \n",
    "    plt.grid(alpha=grid_alpha) \n",
    "    plt.xlabel('Expiry (in years)')\n",
    "    plt.ylabel('Discount factor')\n",
    "    ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "\n",
    "    plt.legend(loc='lower right').set_zorder(100)\n",
    "\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "    \n",
    "plot_shocked_discount_curves(\n",
    "    name = 'dc_linear',\n",
    "    refdate = refdate,\n",
    "    dates = sampling_points_EONIA_dates,\n",
    "    discountFactors = [0.0] * len(sampling_points_EONIA_dates),\n",
    "    daycounterType = daycounter_type_standard,\n",
    "    interpolationType = interpolation_type_standard,\n",
    "    extrapolationType = extrapolation_type_standard,\n",
    "    shockParams = shockParams\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute the change in value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the price of our portfolio\n",
    "# Repeat for every scenario\n",
    "results_dirty = []\n",
    "results_clean = []\n",
    "results_dirty_bondonly = []\n",
    "results_clean_bondonly = []\n",
    "\n",
    "currency = 'EUR'\n",
    "parallel = shockParams.loc[shockParams['Currency'] == currency].loc[0]['Parallel']\n",
    "short = shockParams.loc[shockParams['Currency'] == currency].loc[0]['Short']\n",
    "long = shockParams.loc[shockParams['Currency'] == currency].loc[0]['Long']\n",
    "    \n",
    "shockScenarios = ['ParallelUp', 'ParallelDown', 'ShortUp', 'ShortDown', 'LongUp', 'LongDown', 'Flatten', 'Steepen']\n",
    "\n",
    "for shockScenario in shockScenarios:\n",
    "    dcEONIA = getShockedDiscountCurve(\n",
    "        'dc_linear',\n",
    "        refdate,\n",
    "        sampling_points_EONIA_dates,\n",
    "        data_EONIA_current,\n",
    "        daycounter_type_standard,\n",
    "        interpolation_type_standard,\n",
    "        extrapolation_type_standard,\n",
    "        shockScenario,\n",
    "        parallel/100,\n",
    "        short/100,\n",
    "        long/100\n",
    "    )\n",
    "    \n",
    "#     dcWithSpread = getShockedDiscountCurve(\n",
    "#          'dc_linear_spread',\n",
    "#          refdate,\n",
    "#          sampling_points_EONIA_dates,\n",
    "#          data_EONIA_current + creditspread,\n",
    "#          daycounter_type_standard,\n",
    "#          interpolation_type_standard,\n",
    "#          extrapolation_type_standard,\n",
    "#          shockScenario,\n",
    "#          parallel/100,\n",
    "#          short/100,\n",
    "#          long/100\n",
    "#      )\n",
    "    \n",
    "    pricing_data_simple.discountCurve = dcEONIA # dcWithSpread\n",
    "    pay_leg_pricing_data.discountCurve = dcEONIA\n",
    "    rec_leg_pricing_data.discountCurve = dcEONIA\n",
    "    rec_leg_pricing_data.fixingCurve = dcEONIA\n",
    "    \n",
    "    prBond = pyvacon.pricing.price(pricing_data_simple)\n",
    "    prSwap = analytics.price(ir_swap_pricing_data)\n",
    "    dirty = prBond.getPrice() + prSwap.getPrice()\n",
    "    clean = prBond.getCleanPrice() + prSwap.getCleanPrice()\n",
    "    results_dirty.append(dirty)\n",
    "    results_clean.append(clean)\n",
    "    results_dirty_bondonly.append(prBond.getPrice())\n",
    "    results_clean_bondonly.append(prBond.getCleanPrice())\n",
    "    #print(pricing_data_simple.spec.getObjectId() + ', dirty price: ' + str(results.getPrice()) + \",  clean price: \" + str(results.getCleanPrice()))\n",
    "#print(results_dirty)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the change in value (comparison between our entire portfolio and the bond on its own)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histogramm of the changes/differences in value\n",
    "valDiffsDirty = np.asarray([res - currentValue for res in results_dirty])\n",
    "valDiffsDirtyBondOnly = np.asarray([res - currentValueBond for res in results_dirty_bondonly])\n",
    "fig, (ax1, ax2) = plt.subplots(2, figsize=(16,8))\n",
    "#fig = plt.figure(figsize=(16,8))\n",
    "#ax = fig.gca()\n",
    "\n",
    "# print(currentValue)\n",
    "# print(currentValueBond)\n",
    "#print(results_clean)\n",
    "#print(results_dirty)\n",
    "\n",
    "ax1.grid(alpha=grid_alpha) \n",
    "ax1.bar(shockScenarios, valDiffsDirty/currentValue*100, color=color_main, zorder = 40)\n",
    "ax1.axhline(y=0, xmin=0, xmax=1, color=color_highlight, zorder = 30)\n",
    "ax1.set_ylabel('Change in portfolio value [%]')\n",
    "\n",
    "ax2.grid(alpha=grid_alpha) \n",
    "ax2.bar(shockScenarios, valDiffsDirtyBondOnly/currentValueBond*100, color=color_main, zorder = 40)\n",
    "ax2.axhline(y=0, xmin=0, xmax=1, color=color_highlight, zorder = 30)\n",
    "ax2.set_ylabel('Change in bond value [%]')\n",
    "\n",
    "#fig.text(0.075, 0.5, 'Change in value [%]', ha='center', va='center', rotation='vertical')\n",
    "fig.text(0.5, 0.06, 'Shock Scenario', ha='center', va='center')\n",
    "#plt.ylabel('Change in portfolio value [%]')\n",
    "#plt.xlabel('Shock Scenario')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO\n",
    "- Das Wort 'current' als Beschreibung für die jüngste in den Marktdaten vorhandene EONIA-Kurve stört mich\n",
    "- Farben usw, die mehrfach verwendet werden,nur an einer Stelle zuweisen und anschließend nur noch lesend verwenden?\n",
    "- Underscores statt camelCase verwenden\n",
    "- 'Einheit' der Zinssaetze mit an die Funktionen uebergeben (?) (dezimal, percent, basepoint)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "268.267px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
